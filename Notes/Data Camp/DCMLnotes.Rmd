---
title: 'Data Camp: Machine Learning Notes'
author: "Corey Pang"
date: "6/30/2017"
---

#### Machine Learning
* Machine learning focuses on the development of computer programs that can change when exposed to new data. Construct/use algorithms that learn from data.
* Goal: Building an algorithm to predict the outcome

##### Common Machine Learning Topics
1. Classification
    * Predict category(Qualitative Response) of a new observation 
2. Regression
    * Estimating an actual value and not just category 
3. Clustering 
    * Grouping objects in clusters
        * Similar within each cluster
        * Dissimilar between classes
        
#### Supervised Learning
    * Find a function, f, which can be used to assign a class or value to unseen observations
    * Given a set of labeled observations
    
#### Unsupervised Learning
    * Does not require labeled data 
    
#### Semi-Supervised Learning
    * Some of the data is labeled
    * A lot of the data is unlabeled 
    * Use clustering to group together the similar obervations
    * Using clustering information and classes of labeled observations to assign a class to unlabeled observations
    * This gives you more labeled data to perform supervised learning
    
#### Is the model good?
    1. Accuracy
        * Accuracy = # correct / total number
        * Precision = TP / (TP + FP)
        * Recall = TP / (TP + FN)
    2. Computation time
    3. Interpretability
    
    For Clustering:
    * We want the within variability to be low and the between variability to be high.
        * __Within__ 
            * Within sum of squares (WSS)
            * Diameter 
        * __Between__
            * Between sum of squares (BSS)
            * Dunn's Index: minimal intercluster distance / maximal diameter
Supervised learning: Must be able to predict 
    * Unseen Observations
    
How to split your sets?
    * Typically 3:1
    
* n-fold cross-validation
    * Fold test over dataset n times
    * Each test is 1/n size of the total datset
    
Splitting the data into train and test sets
n <- nrow(df)
shuffled_df <- df[sample(n), ]
train_indices <- 1:round(0.7 * n)
train <- shuffled_df[train_indices, ]
test_indices <- (round(0.7 * n) + 1):n
test <- shuffled_df[test_indices, ]

#### Bias and Variance 
* There are two type of error:
    1. Irreducible error 
        * Should not be minimized, noise
    2. Reducible error
        * The lower this, the better our learning algorithm 
        1. __Bias:__ due to wrong assumptions made
            * Difference between the algorithm and the truth
            * More restrictions lead to higher Bias
        2. __Variance:__ Error due to the sampling of the training set
            * Model with high variance fits the training set closely, which generalizes bad to the test set 
        
    * Bias Variance Trade-off
        * Inverse relationship between Bias and Variance 
    * Overfitting
        * Accuracy will depend on the data set split 
        * High variance will depend heavily on the data set split 
        * Overfitting=Model fits the training set better than the test set 
        * Model is too specific
    * Underfitting
        * Model is restricted too much
        * Model is too general
        
Example Code:
##### Apply spam_classifier to emails_full: pred_full
pred_full <- spam_classifier(emails_full$avg_capital_seq)

##### Build confusion matrix for emails_full: conf_full
conf_full <- table(emails_full$spam, pred_full)

##### Calculate the accuracy with conf_full: acc_full
acc_full <- sum(diag(conf_full))/sum(conf_full)

### Chapter 2: Classification
* Classification: Automatically assigns class to observations with features 

##### Information Gain
* Information gained from split based on feature test 
* Test leads to nicely divided classes
    * High information gain
* Test leads to scrambled classes
    * Low information gain
* Tests with high information gain will be chosen
* The number of nodes influences the chance of overfitting
* Pruning the tree: Restrict size, higher bias 

#### k-Nearest Neighbors
* __Instance based learning__
    * No real model like decision tree
    * Compares unseen instances to training set
    * Predict using the comparison of unseen data to the training set 
    * k-nearest neighbor is an example of instance based learning
        * Finds the closest observation and assigns the same class
        * k is the amount of neighbors
        * Assign class that is most represented in the k neighbors 
        
        * Distance Metric
            1. Euclidean Distance
            2. Manhatten Distance 
            * Scaling can be an issue when the units do not match, it will influence the distance
                * We must normalize all features
            * For categorical variables: Need to create dummy variables that take either a 1 or 0. 
##### Droppinga column
* dropping a column named column in a data frame named df can be done as follows: df$column <- NULL
##### Normalize Pclass
min_class <- min(knn_train$Pclass)
max_class <- max(knn_train$Pclass)
knn_train$Pclass <- (knn_train$Pclass - min_class) / (max_class - min_class)
knn_test$Pclass <- (knn_test$Pclass - min_class) / (max_class - min_class)

* Using KNN in R: 
    * pred <- knn(train = ___, test = ___, cl = ___, k = ___)

#### The Rocc Curve (A performance Measure)
* Very powerful performance measurement 
* For binary classification
* Receiver Operator Characteristic Curve (ROC Curve)
    * True Positive Rate(TPR): TP/(TP+FN)
    * False Positive Rate(FPR): FP/(FP+TN)
    
* __ROC Curve__
    * X-axis: FPR
    * Y-axis: TPR
    * Interpretation of ROC Curve: The better it is, the closer the line it to the top left corner
    * AUC closer to 1
* Drawing the curve in R:
    * library(ROCR)
    * pred_k <- prediction(probs_k, test$spam)
    * perf_t <- performance(pred_t, 'tpr', 'fpr')
    * perf_k <- performance(pred_k, 'tpr', 'fpr')
    * draw_roc_lines(perf_t, perf_k)
    
#### Regression (Supervised)
* Adjusted R-squared
    1. Penalizes more predictors
    2. Used to compare 
    * Assumptions Code:
        1. plot(data$fitted.values, data$residuals)
        2. qqnorm(data$residuals, ylab='Residual Quantiles')

