---
title: 'Data Camp: Machine Learning Notes'
author: "Corey Pang"
date: "6/30/2017"
---

#### Machine Learning
* Machine learning focuses on the development of computer programs that can change when exposed to new data. Construct/use algorithms that learn from data.
* Goal: Building an algorithm to predict the outcome

##### Common Machine Learning Topics
1. Classification
    * Predict category(Qualitative Response) of a new observation 
2. Regression
    * Estimating an actual value and not just category 
3. Clustering 
    * Grouping objects in clusters
        * Similar within each cluster
        * Dissimilar between classes
        
#### Supervised Learning
    * Find a function, f, which can be used to assign a class or value to unseen observations
    * Given a set of labeled observations
    
#### Unsupervised Learning
    * Does not require labeled data 
    
#### Semi-Supervised Learning
    * Some of the data is labeled
    * A lot of the data is unlabeled 
    * Use clustering to group together the similar obervations
    * Using clustering information and classes of labeled observations to assign a class to unlabeled observations
    * This gives you more labeled data to perform supervised learning
    
#### Is the model good?
    1. Accuracy
        * Accuracy = # correct / total number
        * Precision = TP / (TP + FP)
        * Recall = TP / (TP + FN)
    2. Computation time
    3. Interpretability
    
    For Clustering:
    * We want the within variability to be low and the between variability to be high.
        * __Within__ 
            * Within sum of squares (WSS)
            * Diameter 
        * __Between__
            * Between sum of squares (BSS)
            * Dunn's Index: minimal intercluster distance / maximal diameter
Supervised learning: Must be able to predict 
    * Unseen Observations
    
How to split your sets?
    * Typically 3:1
    
* n-fold cross-validation
    * Fold test over dataset n times
    * Each test is 1/n size of the total datset
    
Splitting the data into train and test sets
n <- nrow(df)
shuffled_df <- df[sample(n), ]
train_indices <- 1:round(0.7 * n)
train <- shuffled_df[train_indices, ]
test_indices <- (round(0.7 * n) + 1):n
test <- shuffled_df[test_indices, ]

#### Bias and Variance 
* There are two type of error:
    1. Irreducible error 
        * Should not be minimized, noise
    2. Reducible error
        * The lower this, the better our learning algorithm 
        1. __Bias:__ due to wrong assumptions made
            * Difference between the algorithm and the truth
            * More restrictions lead to higher Bias
        2. __Variance:__ Error due to the sampling of the training set
            * Model with high variance fits the training set closely, which generalizes bad to the test set 
        
    * Bias Variance Trade-off
        * Inverse relationship between Bias and Variance 
    * Overfitting
        * Accuracy will depend on the data set split 
        * High variance will depend heavily on the data set split 
        * Overfitting=Model fits the training set better than the test set 
        * Model is too specific
    * Underfitting
        * Model is restricted too much
        * Model is too general
        
Example Code:
# Apply spam_classifier to emails_full: pred_full
pred_full <- spam_classifier(emails_full$avg_capital_seq)

# Build confusion matrix for emails_full: conf_full
conf_full <- table(emails_full$spam, pred_full)

# Calculate the accuracy with conf_full: acc_full
acc_full <- sum(diag(conf_full))/sum(conf_full)

### Chapter 2: Classification
* Classification: Automatically assigns class to observations with features 

##### Information Gain
* Information gained from split based on feature test 
* Test leads to nicely divided classes
    * High information gain
* Test leads to scrambled classes
    * Low information gain
* Tests with high information gain will be chosen
* The number of nodes influences the chance of overfitting
* Pruning the tree: Restrict size, higher bias 






